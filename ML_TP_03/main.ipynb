{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2CSSID-TP03. Naive Bayes\n",
    "\n",
    "Dans ce TP, nous allons traiter Naive Bayes. C'est le seul algorithme dans notre programme qui cr√©e un mod√®le g√©n√©ratif."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bin√¥mes : \n",
    "- **Bin√¥me 1 : HATTABI ILYES** \n",
    "- **Bin√¥me 2 : CHAHBOUNI SKANDAR RAMZI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.21.5', '1.4.2', '3.5.1')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import numpy             as np\n",
    "import pandas            as pd \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "\n",
    "np        .__version__ , \\\n",
    "pd        .__version__ , \\\n",
    "matplotlib.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List, Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RAPPEL**\n",
    "\n",
    "Tout le monde connait le th√©or√®me de Bayes pour calculer la probabilit√© conditionnelle d'un √©vennement $A$ sachant un autre $B$: \n",
    "$$ P(A|B) = \\frac{P(A)P(B|A)}{P(B)}$$\n",
    "\n",
    "Pour appliquer ce th√©or√®me sur un probl√®me d'appentissage automatique, l'id√©e est simple ; Etant donn√© une caract√©ristique $f$ et la sortie $y$ qui peut avoir la classe $c$ : \n",
    "- Remplacer $A$ par $y=c$\n",
    "- Remplacer $B$ par $f$ \n",
    "On aura l'√©quation : \n",
    "$$ P(y=c|f) = \\frac{P(y=c)P(f|y=c)}{P(f)}$$\n",
    "\n",
    "On appelle : \n",
    "- $P(y=c|f)$ post√©rieure \n",
    "- $P(y=c)$ ant√©rieure\n",
    "- $P(f|y=c)$ vraisemblance\n",
    "- $P(f)$ √©vidence \n",
    "\n",
    "Ici, on estime la probablit√© d'une classe $c$ sachant une caract√©ristique $f$ en utilisant des donn√©es d'entrainement. Maintenant, on veut estimer la probabilit√© d'une classe $c$ sachant un vecteur de caract√©ristiques $\\overrightarrow{f} = \\{f_1, ..., f_L\\}$ : \n",
    "$$ P(y=c|\\overrightarrow{f}) = \\frac{P(y=c)P(\\overrightarrow{f}|y=c)}{P(f)}$$\n",
    "\n",
    "Etant donn√©e plusieurs classes $c_j$, la classe choisie $\\hat{c}$ est celle avec la probabilit√© maximale \n",
    "$$\\hat{c} = \\arg\\max\\limits_{c_k} P(y=c_k|\\overrightarrow{f})$$\n",
    "$$\\hat{c} = \\arg\\max\\limits_{c_k} \\frac{P(y=c_k)P(\\overrightarrow{f}|y=c_k)}{P(f)}$$\n",
    "On supprime l'√©vidence pour cacher le crime : $P(f)$ ne d√©pend pas de $c_k$ et elle est postive, donc √ßa ne va pas affecter la fonction $\\max$.\n",
    "$$\\hat{c} = \\arg\\max\\limits_{c_k} P(y=c_k)P(\\overrightarrow{f}|y=c_k)$$\n",
    "\n",
    "Pour calculer $P(\\overrightarrow{f}|y=c_k)$, on va utiliser une properi√©t√© na√Øve (d'o√π vient le nom Naive Bayes) : on suppose l'ind√©pendence conditionnelle entre les caract√©ristiques $f_j$. \n",
    "$$\\hat{c} = \\arg\\max\\limits_{c_k} P(y=c_k) \\prod\\limits_{f_j \\in \\overrightarrow{f}} P(f_j|y=c_k)$$\n",
    "\n",
    "Pour √©viter la disparition de la probabilit√© (multiplication et repr√©sentation de virgule flottante sur machine), on transforme vers l'espace logarithme.\n",
    "$$\\hat{c} = \\arg\\max\\limits_{c_k} \\log P(y=c_k) + \\sum\\limits_{f_j \\in \\overrightarrow{f}} \\log P(f_j|y=c_k)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## I. R√©alisation des algorithmes\n",
    "\n",
    "Pour estimer la vraisemblance, il existe plusieurs mod√®les (lois):\n",
    "- **Loi multinomiale :** pour les carac√©tristiques nominales\n",
    "- **Loi de Bernoulli :** lorsqu'on est interress√© par l'apparence d'une caract√©ristique ou non (binaire)\n",
    "- **Loi normale :** pour les caract√©ristiques num√©riques\n",
    "\n",
    "Dans ce TP, nous allons impl√©menter Naive Bayes pour les caract√©ristiques nominales (loi multinomiale). \n",
    "Dans notre mod√®le, nous voulons stocker les statistiques et pas les probabilit√©s. \n",
    "L'int√©r√™t est de faciliter la mise √† jours des statistiques (si par exemple, nous avons un autre dataset et nous voulons enrichir le mod√®le ; dans e cas, il suffit d'ajouter les statistiques du nouveau dataset)\n",
    "\n",
    "Ici, nous allons utiliser le dataset \"jouer\" (utilis√© dans la plupart des cours) contenant des caract√©ristiques nominales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temps</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidite</th>\n",
       "      <th>vent</th>\n",
       "      <th>jouer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ensoleile</td>\n",
       "      <td>chaude</td>\n",
       "      <td>haute</td>\n",
       "      <td>non</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ensoleile</td>\n",
       "      <td>chaude</td>\n",
       "      <td>haute</td>\n",
       "      <td>oui</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nuageux</td>\n",
       "      <td>chaude</td>\n",
       "      <td>haute</td>\n",
       "      <td>non</td>\n",
       "      <td>oui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pluvieux</td>\n",
       "      <td>douce</td>\n",
       "      <td>haute</td>\n",
       "      <td>non</td>\n",
       "      <td>oui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pluvieux</td>\n",
       "      <td>fraiche</td>\n",
       "      <td>normale</td>\n",
       "      <td>non</td>\n",
       "      <td>oui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pluvieux</td>\n",
       "      <td>fraiche</td>\n",
       "      <td>normale</td>\n",
       "      <td>oui</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nuageux</td>\n",
       "      <td>fraiche</td>\n",
       "      <td>normale</td>\n",
       "      <td>oui</td>\n",
       "      <td>oui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ensoleile</td>\n",
       "      <td>douce</td>\n",
       "      <td>haute</td>\n",
       "      <td>non</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ensoleile</td>\n",
       "      <td>fraiche</td>\n",
       "      <td>normale</td>\n",
       "      <td>non</td>\n",
       "      <td>oui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pluvieux</td>\n",
       "      <td>douce</td>\n",
       "      <td>normale</td>\n",
       "      <td>non</td>\n",
       "      <td>oui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ensoleile</td>\n",
       "      <td>douce</td>\n",
       "      <td>normale</td>\n",
       "      <td>oui</td>\n",
       "      <td>oui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>nuageux</td>\n",
       "      <td>douce</td>\n",
       "      <td>haute</td>\n",
       "      <td>oui</td>\n",
       "      <td>oui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>nuageux</td>\n",
       "      <td>chaude</td>\n",
       "      <td>normale</td>\n",
       "      <td>non</td>\n",
       "      <td>oui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>pluvieux</td>\n",
       "      <td>douce</td>\n",
       "      <td>haute</td>\n",
       "      <td>oui</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        temps temperature humidite vent jouer\n",
       "0   ensoleile      chaude    haute  non   non\n",
       "1   ensoleile      chaude    haute  oui   non\n",
       "2     nuageux      chaude    haute  non   oui\n",
       "3    pluvieux       douce    haute  non   oui\n",
       "4    pluvieux     fraiche  normale  non   oui\n",
       "5    pluvieux     fraiche  normale  oui   non\n",
       "6     nuageux     fraiche  normale  oui   oui\n",
       "7   ensoleile       douce    haute  non   non\n",
       "8   ensoleile     fraiche  normale  non   oui\n",
       "9    pluvieux       douce  normale  non   oui\n",
       "10  ensoleile       douce  normale  oui   oui\n",
       "11    nuageux       douce    haute  oui   oui\n",
       "12    nuageux      chaude  normale  non   oui\n",
       "13   pluvieux       douce    haute  oui   non"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jouer   = pd.read_csv('data/jouer.csv')\n",
    "\n",
    "X_jouer = jouer.iloc[:, :-1].values # Premi√®res colonnes \n",
    "Y_jouer = jouer.iloc[:,  -1].values # Derni√®re colonne \n",
    "\n",
    "# Afficher le dataset \"jouer\"\n",
    "jouer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.1. Entra√Ænement de la probabilit√© ant√©rieure\n",
    "\n",
    "Etant donn√© le vecteur de sortie $Y$, la probabilit√© de chaque classe (diff√©rentes valeurs de $Y$) est calul√©e comme :\n",
    "\n",
    "$$p(c_k) = \\frac{|\\{y / y \\in Y \\text{ et } y = c_k\\}|}{|Y|}$$\n",
    "\n",
    "\n",
    "La fonction doit r√©cup√©rer des statistiques afin de pouvoir calculer la probabilit√© ant√©rieure de chaque classe. Donc, elle doit retourner  :\n",
    "- Un vecteur contenant les noms des classes\n",
    "- Un vecteur contenant les nombres d'occurrences de chaque classe dans le premier vecteur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['non', 'oui'], dtype=object), array([5, 9], dtype=int64))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Stastistiques sur la probabilit√© ant√©rieure\n",
    "def stat_anterieure(Y: np.ndarray) -> Tuple[np.ndarray, np.ndarray]: \n",
    "    cls, freq  = np.unique(Y, return_counts=True) \n",
    "    return cls, freq\n",
    "\n",
    "#=====================================================================\n",
    "# TEST UNITAIRE\n",
    "#=====================================================================\n",
    "# Resultat : \n",
    "# (array(['non', 'oui'], dtype=object), array([5, 9]))\n",
    "#---------------------------------------------------------------------\n",
    "\n",
    "stat_anterieure(Y_jouer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.2. Entra√Ænement de la probabilit√© de vraissemblance (loi multinomiale)\n",
    "\n",
    "Notre mod√®le doit garder le nombre des diff√©rentes valeurs d'une caract√©ristique $A$ et le nombre de ces valeurs dans chaque classe.\n",
    "Donc, √©tant donn√© un vecteur d'une caract√©ristique $A= X[:,j]$, un autre des $Y$ et un $C$ contenant la liste des classes, la fonction d'entra√Ænement doit retourner : \n",
    "- $V$ : un vecteur contenant les diff√©rentes cat√©gories de $A$ (c'est d√©j√† fait)\n",
    "- Une matrice contenant le nombre d'occurrences de chaque cat√©gorie de $V$ dans chaque classe  : \n",
    "   - Les lignes repr√©sentent les cat√©gories $v \\in V$ de la car√©ct√©ristique $A$\n",
    "   - Les colonnes repr√©sentent les classes $c \\in C$ de $Y$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['ensoleile', 'nuageux', 'pluvieux'], dtype=object),\n",
       " array([[3, 2],\n",
       "        [0, 4],\n",
       "        [2, 3]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Statistiques de vraissemblance (une seule caract√©ristique)\n",
    "def stat_vraissemblance_1(A: np.ndarray, \n",
    "                          Y: np.ndarray, \n",
    "                          C: np.ndarray\n",
    "                         ) -> Tuple[np.ndarray, np.ndarray]: \n",
    "    V = np.unique(A) # Cat√©gories de la caract√©ristique A\n",
    "    nb_rows = V.size\n",
    "    nb_cols = C.size\n",
    "    freq = np.zeros(shape=(nb_rows, nb_cols), dtype=int)\n",
    "\n",
    "    for a, y in zip(A, Y):\n",
    "        # find a in V \n",
    "        ind_x = np.where(V == a)[0][0]\n",
    "        # find y in C\n",
    "        ind_y = np.where(C == y)[0][0]\n",
    "        # frequency \n",
    "        freq[ind_x][ind_y] += 1\n",
    "    return V, freq\n",
    "\n",
    "#=====================================================================\n",
    "# TEST UNITAIRE\n",
    "#=====================================================================\n",
    "# Resultat : \n",
    "# (array(['ensoleile', 'nuageux', 'pluvieux'], dtype=object),\n",
    "#  array([[3, 2],\n",
    "#         [0, 4],\n",
    "#         [2, 3]]))\n",
    "#---------------------------------------------------------------------\n",
    "C_t = np.array(['non', 'oui'])\n",
    "stat_vraissemblance_1(X_jouer[:, 0], Y_jouer, C_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.3. Entra√Ænement loi multinomiale\n",
    "\n",
    "**Rien √† programmer ici**\n",
    "\n",
    "Notre mod√®le ($\\theta_{X, C}$) doit garder des statistiques sur les classes et aussi sur chaque cat√©gorie de chaque caract√©ristique. Pour ce faire, nous allons repr√©senter $\\theta$ comme un vecteur : \n",
    "- $\\theta[N+1]$ est un vecteur de $N$ √©l√©ments repr√©sentant des statistiques sur chaque caract√©ristique $j$, plus un √©l√©ment (le dernier) pour les statistiques sur les classes.\n",
    "- Chaque √©l√©ment est un dictionnaire (HashMap en Java)\n",
    "- Un √©l√©ment des caract√©ristiques contient deux cl√©s : \n",
    "    - **val** : pour r√©cup√©rer la liste des noms des cat√©gories de la caract√©ristique\n",
    "    - **freq**: pour r√©cup√©rer une matrice repr√©sentant la fr√©quence de chaque caract√©ristique dans chaque classe\n",
    "- Un √©l√©ment des classes contient deux cl√©s : \n",
    "    - **cls** : pour r√©cup√©rer la liste des noms des classes\n",
    "    - **freq**: pour r√©cup√©rer la liste des fr√©quences de chaque classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'val': array(['ensoleile', 'nuageux', 'pluvieux'], dtype=object),\n",
       "  'freq': array([[3, 2],\n",
       "         [0, 4],\n",
       "         [2, 3]])},\n",
       " {'val': array(['chaude', 'douce', 'fraiche'], dtype=object),\n",
       "  'freq': array([[2, 2],\n",
       "         [2, 4],\n",
       "         [1, 3]])},\n",
       " {'val': array(['haute', 'normale'], dtype=object),\n",
       "  'freq': array([[4, 3],\n",
       "         [1, 6]])},\n",
       " {'val': array(['non', 'oui'], dtype=object),\n",
       "  'freq': array([[2, 6],\n",
       "         [3, 3]])},\n",
       " {'cls': array(['non', 'oui'], dtype=object),\n",
       "  'freq': array([5, 9], dtype=int64)}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# La fonction qui entraine Th√©ta sur plusieurs caract√©ristiques\n",
    "# Rien √† programmer ici\n",
    "# Notre th√©ta est une liste des dictionnaires;\n",
    "# chaque dictionnaire contient la liste des cat√©gories et la matrice des fr√©quences dela caract√©ristique respective √† la colonne de X\n",
    "# On ajoute les statistiques ant√©rieures des classes √† la fin de r√©sultat\n",
    "def entrainer_multi(X: np.ndarray, \n",
    "                    Y: np.ndarray\n",
    "                   ) -> np.ndarray: \n",
    "    \n",
    "    Theta   = []\n",
    "    \n",
    "    stats_c = {}\n",
    "    stats_c['cls'], stats_c['freq'] =  stat_anterieure(Y)\n",
    "    \n",
    "    for j in range(X.shape[1]): \n",
    "        stats = {}\n",
    "        stats['val'], stats['freq'] =  stat_vraissemblance_1(X[:, j], Y, stats_c['cls'])\n",
    "        Theta.append(stats)\n",
    "    \n",
    "    Theta.append(stats_c)\n",
    "    return Theta\n",
    "\n",
    "\n",
    "#=====================================================================\n",
    "# TEST UNITAIRE\n",
    "#=====================================================================\n",
    "# Resultat : \n",
    "# [{'val': array(['ensoleile', 'nuageux', 'pluvieux'], dtype=object),\n",
    "#   'freq': array([[3, 2],\n",
    "#          [0, 4],\n",
    "#          [2, 3]])},\n",
    "#  {'val': array(['chaude', 'douce', 'fraiche'], dtype=object),\n",
    "#   'freq': array([[2, 2],\n",
    "#          [2, 4],\n",
    "#          [1, 3]])},\n",
    "#  {'val': array(['haute', 'normale'], dtype=object),\n",
    "#   'freq': array([[4, 3],\n",
    "#          [1, 6]])},\n",
    "#  {'val': array(['non', 'oui'], dtype=object),\n",
    "#   'freq': array([[2, 6],\n",
    "#          [3, 3]])},\n",
    "#  {'cls': array(['non', 'oui'], dtype=object), 'freq': array([5, 9])}]\n",
    "#---------------------------------------------------------------------\n",
    "Theta_jouer = entrainer_multi(X_jouer, Y_jouer)\n",
    "\n",
    "Theta_jouer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### I.4. Estimation de la probabilit√© de vraissemblance (loi multinomiale)\n",
    "L'√©quation pour estimer la vraisemblance \n",
    "$$ P(X_j=v|y=c_k) = \\frac{|\\{ y \\in Y / y = c_k \\text{ et } X_j = v\\}|}{|\\{y = c_k\\}|}$$\n",
    "\n",
    "\n",
    "Dans le cas d'une valeur $v$ qui n'existe pas dans le dataset d'entrainnement ou qui n'existe pas pour une classe donn√©e mais ui existe dans le dataset de test, nous aurons une probabilit√© nulle. \n",
    "Afin de r√©gler ce probl√®me, nous pouvons appliquer une fonction de lissage qui attribue une petite probabilit√© aux donn√©es non vues dans l'entra√Ænement. \n",
    "Le lissage que nous allons utiliser est celui de Lidstone. \n",
    "Lorsque $\\alpha = 1$, il est appel√© lissage de Laplace.\n",
    "$$ P(X_j=v|y=c_k) = \\frac{|\\{ y \\in Y / y = c_k \\text{ et } X_j = v\\}| + \\alpha}{|\\{y = c_k\\}| + \\alpha * |V|}$$\n",
    "O√π: \n",
    "- $\\alpha$ est une valeur donn√©e \n",
    "- $V$ est l'ensemble des diff√©rentes valeurs de $f_j$ (le vocabulaire; les cat√©gories)\n",
    "\n",
    "Etant donn√© : \n",
    "- $\\theta_j$ les param√®tres de la caract√©ristique $j$ repr√©sent√©es comme dictionnaire\n",
    "    - **val** : pour r√©cup√©rer la liste des noms des cat√©gories de la caract√©ristique (vocabulaire $V$)\n",
    "    - **freq**: pour r√©cup√©rer une matrice repr√©sentant la fr√©quence de chaque caract√©ristique dans chaque classe. C'est une matrice $|V|\\times|C|$\n",
    "- $v$ la valeur de la caract√©ristique $j$ utilis√©e pour calculer les probabilit√©s\n",
    "- $\\theta_c$ les param√®tres des classes $C$ repr√©sent√©es comme dictionnaire\n",
    "    - **cls** : pour r√©cup√©rer la liste des noms des classes\n",
    "    - **freq**: pour r√©cup√©rer la liste des fr√©quences des classes\n",
    "    \n",
    "Cette fonction doit retourner : \n",
    "- Une liste $P[|C|]$ contenant les probabilit√©s de la cat√©gorie $v$ de $X_j$ sur toutes les classes $C$ \n",
    "- Elle doit prendre en consid√©ration le cas o√π la valeur $v$ n'existe pas dans le mod√®le entra√Æn√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.4, 0.3333333333333333], [0.125, 0.08333333333333333])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Calculer la vraissamblance d'une valeur donn√©e\n",
    "def P_vraiss_multi(Theta_j: Dict[str, np.ndarray], \n",
    "                   Theta_c: Dict[str, np.ndarray], \n",
    "                   v      : str, \n",
    "                   alpha  : float = 0.\n",
    "                  ) -> Tuple[np.ndarray, np.ndarray]: \n",
    "    \n",
    "    #une liste des indices o√π se trouve la valeur v dans Theta_j[\"val\"]\n",
    "    #commentaire de classroom\n",
    "    ind = np.where(Theta_j['val'] == v)[0]\n",
    "    \n",
    "    nbr_diffs = np.unique(Theta_j['val']).size\n",
    "    result = []\n",
    "    for (i , nb_occ) in enumerate(Theta_c['freq']):\n",
    "        if ind.size == 0:\n",
    "            prob = alpha / (nb_occ + alpha * nbr_diffs)\n",
    "        else :\n",
    "            prob = (Theta_j['freq'][ind[0]][i] + alpha) / (nb_occ + alpha * nbr_diffs)\n",
    "        result.append(prob)\n",
    "        \n",
    "    return result\n",
    "\n",
    "#=====================================================================\n",
    "# TEST UNITAIRE\n",
    "#=====================================================================\n",
    "# Resultat : \n",
    "# (array([0.4       , 0.33333333]), array([0.125     , 0.08333333]))\n",
    "#---------------------------------------------------------------------\n",
    "# Calcul :\n",
    "# La probabilit√© de jouer si temps = pluvieux \n",
    "# P(temps = pluvieux | jouer=oui) = (nbr(temps=pluvieux et jouer=oui)+alpha)/(nbr(jour=oui) + alpha * nbr_diff(temps)))\n",
    "# P(temps = pluvieux | jouer=oui) = (3 + 0)/(9 + 0) ==> 3 est le nombre de diff√©rentes valeurs de temps (entrainnement)\n",
    "# P(temps = pluvieux | jouer=oui) = 4/12 ==> 0.33333333333333333333333333333333333~\n",
    "\n",
    "# La probabilit√© de jouer si temps = neigeux \n",
    "# P(temps = neigeux | jouer=oui) = (nbr(temps=neigeux et jouer=oui)+alpha)/(nbr(jouer=oui) + alpha * nbr_diff(temps)))\n",
    "# P(temps = neigeux | jouer=oui) = (0 + 1)/(9 + 3) ==> 3 est le nombre de diff√©rentes valeurs de temps (entrainnement)\n",
    "# P(temps = neigeux | jouer=oui) = 1/13 ==> 0.0833333333333333333333333333333333333~\n",
    "#---------------------------------------------------------------------\n",
    "\n",
    "\n",
    "P_vraiss_multi(Theta_jouer[0], Theta_jouer[-1], 'pluvieux'), \\\n",
    "P_vraiss_multi(Theta_jouer[0], Theta_jouer[-1], 'neigeux', alpha=1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.5. Pr√©diction de la classe (loi multinomiale)\n",
    "Revenons maintenant √† notre √©quation de pr√©diction \n",
    "$$\\hat{c} = \\arg\\max\\limits_{c_k} \\log P(y=c_k) + \\sum\\limits_{f_j \\in \\overrightarrow{f}} \\log P(f_j|y=c_k)$$\n",
    "\n",
    "- On doit pr√©dire un seule √©chantillon $x$. \n",
    "- La fonction doit retourner un vecteur des log-probabilit√© des classes\n",
    "- Si anter=false donc on n'utilise pas la probabilit√© ant√©rieure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-5.20912179, -4.10264337]), array([-4.17950237, -3.66081061]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Pr√©diction des log des probabilit√©s\n",
    "def predire(x    : np.ndarray, \n",
    "            Theta: List[Dict[str, np.ndarray]], \n",
    "            alpha: float = 1., \n",
    "            anter: bool  = True\n",
    "           ) -> float: \n",
    "    \n",
    "    if anter:\n",
    "        result = np.log(Theta[-1]['freq'] / sum(Theta[-1]['freq'])) # probabilit√© ant√©rieure\n",
    "    else :\n",
    "        result = np.zeros(shape=Theta[-1]['cls'].shape)\n",
    "        \n",
    "    for (i, value) in enumerate(x):\n",
    "        result = np.add(result, np.log(P_vraiss_multi(Theta[i], Theta[-1], value, alpha=alpha)))\n",
    "        \n",
    "    return result\n",
    "\n",
    "#=====================================================================\n",
    "# TEST UNITAIRE\n",
    "#=====================================================================\n",
    "# Resultat : \n",
    "# (array([-5.20912179, -4.10264337]), array([-4.17950237, -3.66081061]))\n",
    "#---------------------------------------------------------------------\n",
    "predire(['pluvieux', 'fraiche', 'normale', 'oui'], Theta_jouer), \\\n",
    "predire(['pluvieux', 'fraiche', 'normale', 'oui'], Theta_jouer, anter=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.6. Regrouper en une classe (loi multinomiale)\n",
    "\n",
    "**Rien √† programmer ici**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['oui', 'non']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NBMultinom(object): \n",
    "    \n",
    "    def __init__(self, alpha=1.): \n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def entrainer(self, X, Y):\n",
    "        self.Theta = entrainer_multi(X, Y)\n",
    "    \n",
    "    def predire(self, X, anter=True, prob=False): \n",
    "        Y_pred = []\n",
    "        cls = self.Theta[-1]['cls']\n",
    "        for i in range(len(X)): \n",
    "            log_prob = predire(X[i,:], self.Theta, alpha=self.alpha, anter=anter)\n",
    "            if prob:\n",
    "                Y_pred.append(np.max(log_prob))\n",
    "            else:\n",
    "                Y_pred.append(cls[np.argmax(log_prob)])\n",
    "        return Y_pred\n",
    "\n",
    "#=====================================================================\n",
    "# TEST UNITAIRE\n",
    "#=====================================================================\n",
    "# Resultat : \n",
    "# ['oui', 'non']\n",
    "#---------------------------------------------------------------------\n",
    "notre_modele = NBMultinom()\n",
    "notre_modele.entrainer(X_jouer, Y_jouer)\n",
    "X_test = np.array([\n",
    "    ['neigeux', 'fraiche', 'normale', 'oui'],\n",
    "    ['neigeux', 'fraiche', 'haute'  , 'oui']\n",
    "])\n",
    "notre_modele.predire(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Application et analyse\n",
    "\n",
    "**Il n'y a rien √† programmer ici.**\n",
    "\n",
    "Le but de cette section est de mener des exp√©rimentations afin de bien comprendre les concepts vus dans le cours.\n",
    "Aussi, elle nous assiste √† comprendre l'effet des diff√©rents param√®tres.\n",
    "En plus, la discussion des diff√©rentes exp√©rimentations peut am√©liorer l'aspect analytique chez l'√©tudient.\n",
    "\n",
    "### II.1. Probabilit√© ant√©rieure \n",
    "\n",
    "Nous voulons tester l'effet de la probabilit√© ant√©rieure.\n",
    "Pour ce faire, nous avons entra√Æn√© deux mod√®les :\n",
    "1. Avec probabilit√© ant√©rieure\n",
    "1. Sans probabilit√© ant√©rieure (Il consid√®re une distribution uniforme des classes)\n",
    "\n",
    "Pour tester si les mod√®les ont bien s'adapter au dataset d'entra√Ænement, nous allons les tester sur le m√™me dataset et calculer le rapport de classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avec probabilit√© ant√©rieure (a priori)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         non       1.00      0.80      0.89         5\n",
      "         oui       0.90      1.00      0.95         9\n",
      "\n",
      "    accuracy                           0.93        14\n",
      "   macro avg       0.95      0.90      0.92        14\n",
      "weighted avg       0.94      0.93      0.93        14\n",
      "\n",
      "Sans probabilit√© ant√©rieure (a priori)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         non       0.67      0.80      0.73         5\n",
      "         oui       0.88      0.78      0.82         9\n",
      "\n",
      "    accuracy                           0.79        14\n",
      "   macro avg       0.77      0.79      0.78        14\n",
      "weighted avg       0.80      0.79      0.79        14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# AVEC Scikit-learn\n",
    "# ===================\n",
    "from sklearn.naive_bayes   import CategoricalNB\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.metrics       import classification_report\n",
    "\n",
    "nb_avec     = CategoricalNB(alpha=1.0, fit_prior=True )\n",
    "nb_sans     = CategoricalNB(alpha=1.0, fit_prior=False)\n",
    "\n",
    "enc         = OrdinalEncoder()\n",
    "X_jouer_enc = enc.fit_transform(X_jouer)\n",
    "nb_avec.fit(X_jouer_enc, Y_jouer)\n",
    "nb_sans.fit(X_jouer_enc, Y_jouer)\n",
    "\n",
    "Y_pred_avec = nb_avec.predict(X_jouer_enc)\n",
    "Y_pred_sans = nb_sans.predict(X_jouer_enc)\n",
    "\n",
    "# AVEC notre mod√®le (juste pour voir comment l'utiliser)\n",
    "# =======================================================\n",
    "#notre_modele = NBMultinom()\n",
    "#notre_modele.entrainer(X_jouer, Y_jouer)\n",
    "#Y_notre_ant = notre_modele.predire(X_jouer)\n",
    "#Y_notre_sans_ant = notre_modele.predire(X_jouer, anter=False) \n",
    "\n",
    "# Le rapport de classification\n",
    "\n",
    "\n",
    "print( 'Avec probabilit√© ant√©rieure (a priori)'  )\n",
    "print(classification_report(Y_jouer, Y_pred_avec))\n",
    "\n",
    "print( 'Sans probabilit√© ant√©rieure (a priori)'  )\n",
    "print(classification_report(Y_jouer, Y_pred_sans))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO: Analyser les r√©sultats**\n",
    "    \n",
    "- Que remarquez-vous ?\n",
    "- Est-ce que la probabilit√© ant√©rieure est importante dans ce cas ?\n",
    "- Comment cette probabilit√© affecte le r√©sultat ?\n",
    "- Quand est-ce que nous sommes s√ªrs que l'utilisation de cette probabilit√© est inutile ?\n",
    "\n",
    "**R√©ponse**\n",
    "\n",
    "- Les r√©sultats obtenues dans le mod√®le avec probabilit√© ant√©rieure sont mieux que celui obtenus dans l'autre mod√®le(sans probabilt√© ant√©rieur). le mod√®le 1 (avec probabilt√© ant√©rieur) est meiux que le mod√®le qui n'utilise pas la probabilit√© ant√©rieur\n",
    "- Oui, car les classes de notre dataset ne sont pas uniforme (d√©s√©quilibr√©s).\n",
    "- lorsque les classes sont d√©siquilibr√©s la valeur de probabilit√© ant√©rieur differe, donc l'ajout de cette probabilt√© au probabilt√© post√©rieur peut changer le r√©sultat.\n",
    "- la probabilit√© ant√©rieur n'est pas utile lorsque les classes de dataset sont uniforme, ce qui implique que la probabilit√© ant√©rieur est la meme pour touts les classes .(on rajoute toujours une valeurs constante pour toute les probabilit√©s calcul√© ce qui ne sert √† rien) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.2. Lissage\n",
    "\n",
    "Nous voulons tester l'effet de lissage de Lidstone.\n",
    "Pour ce faire, nous avons entra√Æn√© trois mod√®les : \n",
    "1. alpha = 1 (lissage de Laplace)\n",
    "1. alpha = 0.5\n",
    "1. alpha = 0 (sans lissage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha = 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         non       1.00      0.80      0.89         5\n",
      "         oui       0.90      1.00      0.95         9\n",
      "\n",
      "    accuracy                           0.93        14\n",
      "   macro avg       0.95      0.90      0.92        14\n",
      "weighted avg       0.94      0.93      0.93        14\n",
      "\n",
      "Alpha = 0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         non       1.00      0.80      0.89         5\n",
      "         oui       0.90      1.00      0.95         9\n",
      "\n",
      "    accuracy                           0.93        14\n",
      "   macro avg       0.95      0.90      0.92        14\n",
      "weighted avg       0.94      0.93      0.93        14\n",
      "\n",
      "Alpha = 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         non       1.00      0.80      0.89         5\n",
      "         oui       0.90      1.00      0.95         9\n",
      "\n",
      "    accuracy                           0.93        14\n",
      "   macro avg       0.95      0.90      0.92        14\n",
      "weighted avg       0.94      0.93      0.93        14\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s\\anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:555: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "NBC_10 = CategoricalNB(alpha = 1.0 )\n",
    "NBC_05 = CategoricalNB(alpha = 0.5 )\n",
    "NBC_00 = CategoricalNB(alpha = 0.0 )\n",
    "\n",
    "NBC_10.fit( X_jouer_enc,   Y_jouer )\n",
    "NBC_05.fit( X_jouer_enc,   Y_jouer )\n",
    "NBC_00.fit( X_jouer_enc,   Y_jouer )\n",
    "\n",
    "Y_10   = NBC_10.predict(X_jouer_enc)\n",
    "Y_05   = NBC_05.predict(X_jouer_enc)\n",
    "Y_00   = NBC_00.predict(X_jouer_enc)\n",
    "\n",
    "\n",
    "print(          'Alpha = 1.0'             )\n",
    "print(classification_report(Y_jouer, Y_10))\n",
    "\n",
    "print(          'Alpha = 0.5'             )\n",
    "print(classification_report(Y_jouer, Y_05))\n",
    "\n",
    "print(          'Alpha = 0.0'             )\n",
    "print(classification_report(Y_jouer, Y_00))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO: Analyser les r√©sultats**\n",
    "\n",
    "- Que remarquez-vous ?\n",
    "- Est-ce que le lissage affecte la performance dans ce cas ? Pourquoi ?\n",
    "- Pourquoi Scikit-learn n'accepte pas la valeur $\\alpha=0$ et affiche une alerte \"UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\" ?\n",
    "- Quelle est l'int√©r√™t du lissage (dans le cas g√©n√©ral) ?\n",
    "\n",
    "**R√©ponse**\n",
    "\n",
    "- les trois mod√®les sont identiques, (meme r√©sultats dans tous les m√©trics utilis√©s), changement de alpha n'a pas affect√© la performance des mod√®les.\n",
    "- Non. puisque notre √©chantillon de test ne contient pas des valeurs non √©xistantes dans l'√©chantillon de l'entrainement, en effet data_train = data_test dans notre cas.\n",
    "- Si alpha = 0, alors si dans le test on utilise une valeur que notre mod√®le n'a jamais vu dans l'entrainement, on aurra comme r√©sultat 0.\n",
    "- Dans le cas d'une valeur  ùë£  qui n'existe pas dans le dataset d'entrainnement ou qui n'existe pas pour une classe donn√©e mais elle existe dans le dataset de test, nous aurons une probabilit√© nulle. Afin de r√©gler ce probl√®me, nous pouvons appliquer une fonction de lissage qui attribue une petite probabilit√© aux donn√©es non vues dans l'entra√Ænement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.3. Comparaison avec d'autres algorithmes\n",
    "\n",
    "Naive Bayes est un algorithme puissant lorsqu'il s'agit de classer les documents textuels ; nous voulons tester cette information avec la d√©tection de spam. \n",
    "Le dataset utilis√© est [SMS Spam Collection Dataset](https://www.kaggle.com/uciml/sms-spam-collection-dataset).\n",
    "Chaque message du dataset doit √™tre repr√©sent√© sous forme d'un mod√®le \"Sac √† mots\" (BoW : Bag of Words).\n",
    "Dans l'entra√Ænement, les diff√©rents mots qui s'apparaissent dans les messages (vocabulaire) sont consid√©r√©s comme des caract√©ristiques. \n",
    "Donc, pour chaque message, la valeur de la caract√©ristique est la fr√©quence du mot dans le message. \n",
    "Par exemple, si le mot \"good\" apparait 3 fois dans le message, donc la caract√©ristique \"good\" aura la valeur 3 dans ce message.\n",
    "\n",
    "Notre impl√©mentation n'est pas ad√©quate pour la nature de ce probl√®me. \n",
    "Dans Scikit-learn, [sklearn.naive_bayes.CategoricalNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.CategoricalNB.html) est similaire √† notre impl√©mentation. \n",
    "L'algorithme ad√©quat pour ce type de probl√®me est [sklearn.naive_bayes.MultinomialNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html).\n",
    "Les algorithmes compar√©s :\n",
    "1. Naive Bayes (Loi Multinomiale)\n",
    "1. Naive Bayes (Loi Gaussienne)\n",
    "1. Regression logistique "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texte</th>\n",
       "      <th>classe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               texte classe\n",
       "0  Go until jurong point, crazy.. Available only ...    ham\n",
       "1                      Ok lar... Joking wif u oni...    ham\n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...   spam\n",
       "3  U dun say so early hor... U c already then say...    ham\n",
       "4  Nah I don't think he goes to usf, he lives aro...    ham"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lire le dataset\n",
    "messages = pd.read_csv('data/spam.csv', encoding='latin-1')\n",
    "# renomer les caract√©ristiques : texte et classe\n",
    "messages = messages.rename(columns={'v1': 'classe', 'v2': 'texte'})\n",
    "# garder seulement ces deux caract√©ristiques\n",
    "messages = messages.filter(['texte', 'classe'])\n",
    "\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fin\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection         import train_test_split\n",
    "from sklearn.naive_bayes             import MultinomialNB, GaussianNB\n",
    "from sklearn.linear_model            import LogisticRegression\n",
    "from sklearn.metrics                 import precision_score, recall_score\n",
    "import timeit\n",
    "\n",
    "\n",
    "modeles = [\n",
    "    MultinomialNB(),\n",
    "    GaussianNB(),\n",
    "    LogisticRegression(solver='lbfgs') \n",
    "    #solver=sag est plus lent; donc j'ai choisi le plus rapide\n",
    "]\n",
    "\n",
    "temps_train = []\n",
    "temps_test  = []\n",
    "rappel      = []\n",
    "precision   = []\n",
    "\n",
    "msg_train, msg_test, Y_train, Y_test = train_test_split(messages['texte'] ,\n",
    "                                                        messages['classe'],\n",
    "                                                        test_size    = 0.2, \n",
    "                                                        random_state = 0  )\n",
    "\n",
    "count_vectorizer = CountVectorizer()\n",
    "X_train          = count_vectorizer.fit_transform(msg_train).toarray()\n",
    "X_test           = count_vectorizer.transform    (msg_test ).toarray()\n",
    "\n",
    "\n",
    "for modele in modeles:\n",
    "    # ==================================\n",
    "    # ENTRAINEMENT \n",
    "    # ==================================\n",
    "    temps_debut = timeit.default_timer()\n",
    "    modele.fit(X_train, Y_train)\n",
    "    temps_train.append(timeit.default_timer() - temps_debut)\n",
    "    \n",
    "    # ==================================\n",
    "    # TEST \n",
    "    # ==================================\n",
    "    temps_debut = timeit.default_timer()\n",
    "    Y_pred      = modele.predict(X_test)\n",
    "    temps_test.append(timeit.default_timer() - temps_debut)\n",
    "    \n",
    "    # ==================================\n",
    "    # PERFORMANCE \n",
    "    # ==================================\n",
    "    # Ici, nous consid√©rons une classification binaire avec une seule classe \"spam\" \n",
    "    # le classifieur ne sera pas jug√© par sa capacit√© de d√©tecter les non spams\n",
    "    precision.append(precision_score(Y_test, Y_pred, pos_label='spam'))\n",
    "    rappel   .append(recall_score   (Y_test, Y_pred, pos_label='spam'))\n",
    "\n",
    "    \n",
    "print('Fin') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II.3.1. Temps d'entra√Ænement et de test\n",
    "\n",
    "Combien de temps chaque algorithme prend pour entrainer le m√™me dataset d'entrainement et combien de temps pour tester le m√™me dataset de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithme</th>\n",
       "      <th>Temps d'entrainement</th>\n",
       "      <th>Temps de test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes Multinomial</td>\n",
       "      <td>0.543450</td>\n",
       "      <td>0.068078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Naive Bayes Gaussien</td>\n",
       "      <td>0.431447</td>\n",
       "      <td>0.133568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Regression logistique</td>\n",
       "      <td>1.405087</td>\n",
       "      <td>0.021132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Algorithme  Temps d'entrainement  Temps de test\n",
       "0  Naive Bayes Multinomial              0.543450       0.068078\n",
       "1     Naive Bayes Gaussien              0.431447       0.133568\n",
       "2    Regression logistique              1.405087       0.021132"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo_noms = ['Naive Bayes Multinomial', 'Naive Bayes Gaussien', 'Regression logistique']\n",
    "\n",
    "pd.DataFrame({\n",
    "    'Algorithme'            : algo_noms  ,\n",
    "    'Temps d\\'entrainement' : temps_train,\n",
    "    'Temps de test'         : temps_test\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO: Analyser les r√©sultats**\n",
    "\n",
    "- Que remarquez-vous concernant le temps d'entrainement ? Pourquoi nous avons eu ces r√©sultats en se basant sur les algorithmes ?\n",
    "- Que remarquez-vous concernant le temps de test ? Pourquoi nous avons eu ces r√©sultats en se basant sur les algorithmes ?\n",
    "\n",
    "**R√©ponse**\n",
    "\n",
    "- On remarque que Naive bayes Multinomial et Gaussian sont t√©rs plus rapide que la r√©gression logistique. car la m√©thode de naive bayes est une m√©thode statistique (calcul de probabilit√©) tandis que la r√©gression logistique est une m√©thode it√©rative (dans scikit learn) tous d√©pend de taux d'apprentissage.\n",
    "- On remarque que l'inverse est vrai pour le temps de test, car la regression logistique classifie les valeurs du dataset de test en calculant la sortie en utilisant une fonction de classification (calculs simple) ce qui implique un temp de test court, par contre le naive bayes n√©cessite un calcul des probabilit√© en calculant la somme de toutes les probabilit√©s calcul√©s dans l'entrainement ce qui n√©cessite un temps un peu plus √©leve que la pr√©diction par la regression logistique "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II.3.2. Qualit√© de pr√©diction\n",
    "\n",
    "Comment chaque algorithme performe sur le dataset de test dans le cas de d√©tection de spams (spam: est la classe positive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithme</th>\n",
       "      <th>Rappel</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes Multinomial</td>\n",
       "      <td>0.927711</td>\n",
       "      <td>0.987179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Naive Bayes Gaussien</td>\n",
       "      <td>0.891566</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Regression logistique</td>\n",
       "      <td>0.855422</td>\n",
       "      <td>0.986111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Algorithme    Rappel  Precision\n",
       "0  Naive Bayes Multinomial  0.927711   0.987179\n",
       "1     Naive Bayes Gaussien  0.891566   0.616667\n",
       "2    Regression logistique  0.855422   0.986111"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\n",
    "    'Algorithme' : algo_noms,\n",
    "    'Rappel'     : rappel   ,\n",
    "    'Precision'  : precision\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO: Analyser les r√©sultats**\n",
    "\n",
    "On remarque que Naive Bayes surpasse la r√©gression logistique pour la d√©tection de spams. \n",
    "- Est-ce que ceci preuve que Naive Bayes est meilleur que les autres algorithmes sur n'importe quel probl√®me ?\n",
    "- Est-ce que ceci preuve que Naive Bayes peut donner de meilleurs r√©sultats que les autres algorithmes sur des probl√®mes similaires ?\n",
    "- Pourquoi le mod√®le gaussien est moins performant que le multinomial ?\n",
    "\n",
    "**R√©ponse**\n",
    "\n",
    "- Non. \n",
    "- Oui.\n",
    "- car le model de naive bayes multinomial est utilis√© pour la classification selon des caract√©ristiques discrete (non continue), alors que le naive bayes gaussien est utilis√© pour les distributions continues (distribution normale). dans notre cas, les caract√©ristuqes sont discretes c'est pourquoi le mod√®le multinoimiale est plus performant que l'autre (gaussienne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIN\n"
     ]
    }
   ],
   "source": [
    "print('FIN')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
